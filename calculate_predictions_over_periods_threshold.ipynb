{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load aggregates dataframe\n",
    "aggregates_df = pd.read_csv('llm_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate period predictions using threshold method\n",
    "def calculate_period_predictions(aggregates_df, threshold=0.5):\n",
    "    # Group by match_id and period_id\n",
    "    period_predictions = []\n",
    "    for (match_id, period_id), group in aggregates_df.groupby(['match_id', 'period_id']):\n",
    "        # Calculate the proportion of 1s in the predicted labels\n",
    "        proportion_of_ones = group['predicted_label'].mean()\n",
    "        \n",
    "        # Assign a prediction of 1 if the proportion is above the threshold, otherwise 0\n",
    "        period_prediction = 1 if proportion_of_ones > threshold else 0\n",
    "        \n",
    "        period_predictions.append({\n",
    "            'match_id': match_id,\n",
    "            'period_id': period_id,\n",
    "            'proportion_of_ones': proportion_of_ones,\n",
    "            'period_prediction': period_prediction\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(period_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def find_optimal_threshold(aggregates_df, thresholds):\n",
    "    best_threshold = 0\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        period_predictions_df = calculate_period_predictions(aggregates_df, threshold)\n",
    "        \n",
    "        # Calculate period-level labels\n",
    "        period_labels_df = aggregates_df.groupby(['match_id', 'period_id'])['label'].first().reset_index()\n",
    "        \n",
    "        # Merge period predictions with period labels\n",
    "        merged_df = period_predictions_df.merge(period_labels_df, on=['match_id', 'period_id'])\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(merged_df['label'], merged_df['period_prediction'])\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_accuracy\n",
    "\n",
    "# Define a range of thresholds to test\n",
    "thresholds = [i * 0.01 for i in range(0, 101)]\n",
    "\n",
    "# Find the optimal threshold\n",
    "optimal_threshold, optimal_accuracy = find_optimal_threshold(aggregates_df, thresholds)\n",
    "print(f'Optimal Threshold: {optimal_threshold}')\n",
    "print(f'Optimal Accuracy: {optimal_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating predictions over evaluation set using the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation set\n",
    "import os\n",
    "\n",
    "evaluation_df = pd.read_csv('cleaned_eval_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model = RobertaForSequenceClassification.from_pretrained('./saved_model')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./saved_model')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Ensure the model is on the GPU\n",
    "model.to('cuda')\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate aggregates over the evaluation set\n",
    "\n",
    "# Define the token limit\n",
    "TOKEN_LIMIT = 512\n",
    "\n",
    "# Function to preprocess and aggregate tweets with a progress bar\n",
    "def create_aggregates(df, tokenizer, token_limit, num_aggregates=30, eval=False):\n",
    "    import random\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    aggregates = []\n",
    "    \n",
    "    # Group by MatchID and PeriodID\n",
    "    for (match_id, period_id), group in tqdm(df.groupby(['MatchID', 'PeriodID']), desc=\"Aggregating Tweets\"):\n",
    "        tweets = group['Tweet'].tolist()\n",
    "        if not eval:\n",
    "            event_type = group['EventType'].iloc[0]  # Binary target for the period\n",
    "\n",
    "        # Generate aggregates for this group\n",
    "        for _ in range(num_aggregates):\n",
    "            random.shuffle(tweets)  # Shuffle tweets for randomness\n",
    "            aggregate = \"\"\n",
    "            token_count = 0\n",
    "\n",
    "            for tweet in tweets:\n",
    "                # Tokenize tweet and count tokens\n",
    "                tokenized_tweet = tokenizer.encode(tweet, add_special_tokens=False)\n",
    "                if token_count + len(tokenized_tweet) > token_limit:\n",
    "                    break  # Stop adding tweets if token limit is reached\n",
    "                \n",
    "                # Add the tweet to the aggregate\n",
    "                aggregate += tweet + \" \"\n",
    "                token_count += len(tokenized_tweet)\n",
    "\n",
    "            if not eval:\n",
    "                # Save the aggregate and its label\n",
    "                aggregates.append({\n",
    "                    'text': aggregate.strip(),\n",
    "                    'label': event_type,\n",
    "                    'match_id': match_id,\n",
    "                    'period_id': period_id\n",
    "                })\n",
    "            else:\n",
    "                # Save the aggregate\n",
    "                aggregates.append({\n",
    "                    'text': aggregate.strip(),\n",
    "                    'match_id': match_id,\n",
    "                    'period_id': period_id\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(aggregates)\n",
    "\n",
    "eval_aggregates_df = create_aggregates(evaluation_df, tokenizer, TOKEN_LIMIT, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_aggregates_df.to_csv('eval_aggregates_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=TOKEN_LIMIT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions using model\n",
    "\n",
    "eval_dataset = Dataset.from_pandas(eval_aggregates_df)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "dataloader = DataLoader(tokenized_eval_dataset, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader, desc=\"Making Predictions\"):\n",
    "        inputs = {key: batch[key].to(model.device) for key in ['input_ids', 'attention_mask']}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        batch_predictions = torch.argmax(logits, dim=-1).cpu().tolist()\n",
    "        predictions.extend(batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to the aggregates DataFrame\n",
    "eval_aggregates_df['predicted_label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions using optimal threshold\n",
    "eval_period_predictions_df = calculate_period_predictions(eval_aggregates_df, optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the required columns\n",
    "new_df = pd.DataFrame({\n",
    "    'ID': eval_period_predictions_df['match_id'].astype(str) + '_' + eval_period_predictions_df['period_id'].astype(str),\n",
    "    'EventType': eval_period_predictions_df['period_prediction']\n",
    "})\n",
    "\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "new_df.to_csv('eval_set_predictions_threshold.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
