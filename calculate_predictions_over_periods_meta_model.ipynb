{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load aggregates dataframe with model predictions\n",
    "llm_results = pd.read_csv('llm_predictions_no_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>match_id</th>\n",
       "      <th>period_id</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  match_id  period_id  predicted_label\n",
       "0      0         0          0                0\n",
       "1      0         0          0                0\n",
       "2      0         0          0                0\n",
       "3      0         0          0                0\n",
       "4      0         0          0                0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 17, 18, 19}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect MatchIDs present in the dataset\n",
    "set(llm_results['match_id'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches from 0 to 17 will be our training data, while matches 18 and 19 will be our test data\n",
    "\n",
    "train_llm_results = llm_results[llm_results['match_id'] < 18]\n",
    "test_llm_results = llm_results[llm_results['match_id'] >= 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features dataframe\n",
    "features_df = (\n",
    "    train_llm_results.groupby([\"match_id\", \"period_id\", \"label\"])[\"predicted_label\"]\n",
    "    .value_counts()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Renaming columns for clarity\n",
    "features_df.columns = [\"match_id\", \"period_id\", \"label\", \"count_0\", \"count_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_df = (\n",
    "    test_llm_results.groupby([\"match_id\", \"period_id\", \"label\"])[\"predicted_label\"]\n",
    "    .value_counts()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Renaming columns for clarity\n",
    "test_features_df.columns = [\"match_id\", \"period_id\", \"label\", \"count_0\", \"count_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>period_id</th>\n",
       "      <th>label</th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  period_id  label  count_0  count_1\n",
       "0         0          0      0       29        1\n",
       "1         0          1      0       30        0\n",
       "2         0          2      0       30        0\n",
       "3         0          3      0       30        0\n",
       "4         0          4      0       30        0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on match_id: 0\n",
      "Training on match_id: 1\n",
      "Training on match_id: 2\n",
      "Training on match_id: 3\n",
      "Training on match_id: 4\n",
      "Training on match_id: 5\n",
      "Training on match_id: 7\n",
      "Training on match_id: 8\n",
      "Training on match_id: 10\n",
      "Training on match_id: 11\n",
      "Training on match_id: 12\n",
      "Training on match_id: 13\n",
      "Training on match_id: 14\n",
      "Training on match_id: 17\n",
      "\n",
      "Training Accuracy: 0.87\n",
      "Testing Accuracy: 0.91\n",
      "Final Training Accuracy: 0.87\n",
      "Final Testing Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Dataset class\n",
    "class MatchDataset(Dataset):\n",
    "    def __init__(self, df, has_labels=True):\n",
    "        self.data = df[[\"period_id\", \"count_0\", \"count_1\"]].values\n",
    "        self.has_labels = has_labels\n",
    "        if has_labels:\n",
    "            self.labels = df[\"label\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.has_labels:\n",
    "            return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        else:\n",
    "            return torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)  # Only use the last hidden state\n",
    "        output = self.fc(h_n[-1])  # h_n[-1] is the hidden state of the last LSTM layer\n",
    "        return output\n",
    "\n",
    "# Training function\n",
    "def train_lstm_on_matches(model, criterion, optimizer, features_df, num_epochs=5):\n",
    "    model.train()\n",
    "    match_ids = features_df[\"match_id\"].unique()\n",
    "    \n",
    "    for match_id in match_ids: # Iterate over each match during training\n",
    "        print(f\"Training on match_id: {match_id}\")\n",
    "        match_data = features_df[features_df[\"match_id\"] == match_id]\n",
    "        dataset = MatchDataset(match_data)\n",
    "        dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0.0\n",
    "            for features, labels in dataloader:\n",
    "                features = features.unsqueeze(0)  # Add batch dimension\n",
    "                labels = labels.unsqueeze(1)  # Ensure labels match output shape (batch_size, 1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels.view_as(outputs))  # Match target shape to model output\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in dataloader:\n",
    "            features = features.unsqueeze(0)  # Add batch dimension\n",
    "            outputs = model(features)\n",
    "            predictions = torch.sigmoid(outputs).round()  # Convert logits to binary predictions\n",
    "            correct += (predictions.view_as(labels).long() == labels.long()).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "# Main workflow\n",
    "def main_workflow(features_df, test_features_df, num_epochs=50):\n",
    "    input_dim = 3  # period_id, count_0, count_1\n",
    "    hidden_dim = 16\n",
    "    output_dim = 1  # Predicting the label\n",
    "    num_layers = 1\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers)\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy for binary classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Train the model on the training data\n",
    "    train_lstm_on_matches(model, criterion, optimizer, features_df, num_epochs)\n",
    "\n",
    "    # Evaluate accuracy on the entire training set\n",
    "    train_dataset = MatchDataset(features_df)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "    train_accuracy = calculate_accuracy(model, train_dataloader)\n",
    "    print(f\"\\nTraining Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "    # Evaluate accuracy on the test set\n",
    "    test_dataset = MatchDataset(test_features_df)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    test_accuracy = calculate_accuracy(model, test_dataloader)\n",
    "    print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    return model, train_accuracy, test_accuracy\n",
    "\n",
    "# Execute the workflow\n",
    "model, train_accuracy, test_accuracy = main_workflow(features_df, test_features_df, num_epochs=5)\n",
    "print(f\"Final Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Final Testing Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate predictions over evaluation data using the meta-model we trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>period_id</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  period_id  predicted_label\n",
       "0         6          0                0\n",
       "1         6          0                0\n",
       "2         6          0                0\n",
       "3         6          0                0\n",
       "4         6          0                0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv('eval_aggregates_predictions.csv').drop(columns=['text'])\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_features_df = (\n",
    "    eval_df.groupby([\"match_id\", \"period_id\"])[\"predicted_label\"]\n",
    "    .value_counts()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Renaming columns for clarity\n",
    "eval_features_df.columns = [\"match_id\", \"period_id\", \"count_0\", \"count_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>period_id</th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  period_id  count_0  count_1\n",
       "0         6          0       27        3\n",
       "1         6          1       22        8\n",
       "2         6          2       29        1\n",
       "3         6          3       22        8\n",
       "4         6          4       26        4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  EventType\n",
      "0  6_0          0\n",
      "1  6_1          0\n",
      "2  6_2          0\n",
      "3  6_3          0\n",
      "4  6_4          0\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate predictions and store them in a new DataFrame\n",
    "def generate_predictions_dataframe(model, eval_df):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ids = []\n",
    "\n",
    "    # Create dataset and dataloader without labels\n",
    "    eval_dataset = MatchDataset(eval_df, has_labels=False)\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, features in enumerate(eval_dataloader):\n",
    "            features = features.unsqueeze(0)  # Add batch dimension\n",
    "            outputs = model(features)\n",
    "            predicted_label = torch.sigmoid(outputs).round().item()  # Convert logits to binary prediction\n",
    "\n",
    "            # Generate the ID in the format MatchID_PeriodID\n",
    "            match_id = eval_df.iloc[idx][\"match_id\"]\n",
    "            period_id = eval_df.iloc[idx][\"period_id\"]\n",
    "            id_str = f\"{match_id}_{period_id}\"\n",
    "\n",
    "            ids.append(id_str)\n",
    "            predictions.append(int(predicted_label))\n",
    "\n",
    "    # Create a new DataFrame with the results\n",
    "    result_df = pd.DataFrame({\"ID\": ids, \"EventType\": predictions})\n",
    "    return result_df\n",
    "\n",
    "# Generate predictions\n",
    "predictions_df = generate_predictions_dataframe(model, eval_features_df)\n",
    "\n",
    "print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "1    301\n",
       "0    215\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"EventType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('predictions_llm_plus_lstm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
